{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepfashion mask rcnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b0iaT08-s0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # https://machinelearningmastery.com/how-to-perform-object-detection-in-photographs-with-mask-r-cnn-in-keras/\n",
        "# # https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/\n",
        "# # https://www.pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/\n",
        "# # https://towardsdatascience.com/webcam-object-detection-with-mask-r-cnn-on-google-colab-b3b012053ed1\n",
        "\n",
        "# tensorflow_version 1.x\n",
        "\n",
        "\n",
        "# #change add the Mask_RCNN directory to files. \n",
        "# # example: replace 'mrcnn' with:\n",
        "# # Mask_RCNN.mrcnn\n",
        "\n",
        "# # install mask_rcnn library or it's better to upload it, with the custom files.\n",
        "# !git clone https://github.com/matterport/Mask_RCNN.git\n",
        "\n",
        "# #istall some libraries from tpu\n",
        "# #!git clone https://github.com/tensorflow/tpu/\n",
        "\n",
        "# # import libraries required for the mask_rcnn library\n",
        "# !pip3 install -r 'Mask_RCNN/requirements.txt'\n",
        "# !cd Mask_RCNN ; python setup.py install\n",
        "\n",
        "# # download the Microsoft-coco dataset, in the mask_rcnn folder \n",
        "# !cd Mask_RCNN; wget 'https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5'\n",
        "\n",
        "# # download the an image of an elephant\n",
        "# !wget 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/03/elephant.jpg'\n",
        "\n",
        "# #download an image of a car\n",
        "# !wget 'https://i.insider.com/5d9b5bff52887931e8497a36'\n",
        "\n",
        "# # kangaroo dataset\n",
        "# !git clone https://github.com/experiencor/kangaroo.git\n",
        "# !cd\n",
        "\n",
        "# !unzip '/content/drive/My Drive/machinelearningdataset/DeepFashion2.zip'\n",
        "# print('')\n",
        "# print('')\n",
        "# print ('###################################all done###################################')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Lv55cZ_YKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # unzip deepfashion2 \n",
        "# # there's a file download limit for files from google drive. switch between the shared files from\n",
        "# # deepfashion2 and the files saved on the drive\n",
        "\n",
        "# #shared deepfashion2 dataset.\n",
        "# #!unzip -P 2019Deepfashion2** '/content/drive/My Drive/DeepFashion2 Dataset/json_for_validation.zip'\n",
        "\n",
        "# #  deepfashion2 dataset saved on google drive\n",
        "# !unzip -P 2019Deepfashion2** '/content/drive/My Drive/machinelearningdataset/json_for_validation.zip'\n",
        "# print('\\n','##########################done upzipping files.###########################################')\n",
        "# !unzip -P 2019Deepfashion2** '/content/drive/My Drive/machinelearningdataset/test.zip'\n",
        "# print('\\n','##########################done upzipping test files.###########################################')\n",
        "# !unzip -P 2019Deepfashion2** '/content/drive/My Drive/machinelearningdataset/train.zip'\n",
        "# print('\\n','##########################done upzipping train files.###########################################')\n",
        "# !unzip -P 2019Deepfashion2** '/content/drive/My Drive/machinelearningdataset/validation.zip'\n",
        "# print('\\n','##########################done upzipping validation files.###########################################')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "# create a virtual environment to run older version of tensorflow\n",
        "# mask rcnn runs on tf version 1.x\n",
        "\n",
        "# running venv on jupyter\n",
        "!python3 -m pip install --upgrade pip\n",
        "!python3 -m venv virtual_fashion\n",
        "!source virtual_fashion/bin/activate\n",
        "# !ipython kernel install --user --navirtual_fashion\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# running venv on jupyter\n",
        "!pip3 list\n",
        "\n",
        "\n",
        "#double cheking tf version. inside the venv, tf==1.15, outside, it's tf>2.0\n",
        "!python3 -c 'import tensorflow as tf; print(tf.__version__)'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setups related to  mask rcnn \n",
        "!pip3 install -r 'Mask_RCNN/requirements.txt'\n",
        "!cd Mask_RCNN ; python3 setup.py install\n",
        "# making sure that everything got installed properly\n",
        "!pip3 show mask-rcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huRej0wRVl3o",
        "colab_type": "code",
        "outputId": "55781cc1-a4d0-43f9-97da-345df6e1fa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# convert the annonations to coco-compatible\n",
        "\n",
        "# upload the custom files (visualize.py and model.py) from 7gate_folder>Mask_RCNN>mrcnn\n",
        "# replace the deepfashion2_to_coco.py file in the DeepFashion2>evalation. from 7gate folder\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "img_folder_path = 'train/image'\n",
        "dirListing = os.listdir(img_folder_path)\n",
        "\n",
        "num_images= len(dirListing)\n",
        "print(num_images)\n",
        "!python DeepFashion2/evaluation/deepfashion2_to_coco.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0U9z7jrxgdG",
        "colab_type": "code",
        "outputId": "1064510a-ec97-4c6f-d220-274d96a87fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from os import listdir\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "images_dir =  'train/image/'\n",
        "annotations_dir = 'train/annos/'\n",
        "count_index=0\n",
        "inner_count=0\n",
        "b_box=[]\n",
        "segmentationssss=list()\n",
        "category_id=list()\n",
        "width=list()\n",
        "height=[]\n",
        "for filename in listdir(images_dir):\n",
        "  count_index+=1\n",
        "  image_id = filename[:-4]\n",
        "  direecewdew= 'train/annos/' + image_id +'.json'\n",
        "  with open(direecewdew) as f:\n",
        "    data = f.read()\n",
        "    jsondata = json.loads(data)\n",
        "    for number in range(1,10):\n",
        "      item_number='item'+ str(number)\n",
        "      #print(item_number)\n",
        "      try:\n",
        "        b_box_iterate=jsondata.get(item_number)['bounding_box']\n",
        "        b_box.append(b_box_iterate)\n",
        "        segment=jsondata.get(item_number)['segmentation']\n",
        "        segmentationssss.append(segment)\n",
        "        category=jsondata.get(item_number)['category_id']\n",
        "        category_id.append(category)\n",
        "        w=b_box_iterate[2]\n",
        "        width.append(w)\n",
        "        h=b_box_iterate[3]\n",
        "        height.append(h)\n",
        "        img_path = images_dir + filename\n",
        "        ann_path = annotations_dir + image_id + '.json'\n",
        "        #self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "        #print(inner_count)\n",
        "        inner_count=+1\n",
        "        #print(inner_count)\n",
        "        #print(item_number)  \n",
        "      except Exception:\n",
        "        pass\n",
        "\n",
        "height=np.array(height)\n",
        "width=np.array(width)\n",
        "b_box=np.array(b_box)\n",
        "height=min(height)\n",
        "width=min(width)\n",
        "# print(count_index)\n",
        "# print(b_box)\n",
        "# print(height)\n",
        "# print(width)\n",
        "# print(segmentationssss)\n",
        "# print(category_id)\n",
        "# print(inner_count)\n",
        "\n",
        "print(len(b_box))\n",
        "print(height)\n",
        "print(int(np.mean(width)))\n",
        "\n",
        "#try it now.\n",
        "# there should be no more list eror in masks=zeroes[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9oLkGnqEPXb",
        "colab_type": "code",
        "outputId": "a2b64a3d-917d-4068-cd3c-cfd3dfe7cd4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from os import listdir\n",
        "import json\n",
        "import numpy as np\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from Mask_RCNN.mrcnn.utils import Dataset\n",
        "from Mask_RCNN.mrcnn.config import Config\n",
        "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
        "\n",
        "\n",
        "# class that defines and loads the kangaroo dataset\n",
        "class FashionDataset(Dataset):\n",
        "  def load_dataset(self, dataset_dir, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"fashion\")\n",
        "    images_dir =  'train/image/'\n",
        "    annotations_dir = 'train/annos/'\n",
        "    count_index=0\n",
        "    b_box=[]\n",
        "    segmentationssss=list()\n",
        "    category_id=list()\n",
        "    width=[]\n",
        "    height=[]\n",
        "    for filename in listdir(images_dir):\n",
        "      count_index+=1\n",
        "      image_id = filename[:-4]\n",
        "      direecewdew= 'train/annos/' + image_id +'.json'\n",
        "      with open(direecewdew) as f:\n",
        "        data = f.read()\n",
        "        jsondata = json.loads(data)\n",
        "        for number in range(1,10):\n",
        "          item_number='item'+ str(number)\n",
        "          try:\n",
        "            b_box_iterate=jsondata.get(item_number)['bounding_box']\n",
        "            b_box.append(b_box_iterate)\n",
        "            segment=jsondata.get(item_number)['segmentation']\n",
        "            segmentationssss.append(segment)\n",
        "            category=jsondata.get(item_number)['category_id']\n",
        "            category_id.append(category)\n",
        "            w=b_box_iterate[2]\n",
        "            width.append(w)\n",
        "            h=b_box_iterate[3]\n",
        "            height.append(h)\n",
        "            img_path = images_dir + filename\n",
        "            ann_path = annotations_dir + image_id + '.json'\n",
        "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "          except Exception:\n",
        "            pass\n",
        "    \n",
        "    height=np.array(height)\n",
        "    width=np.array(width)\n",
        "    b_box=np.array(b_box)\n",
        "    height=max(height)\n",
        "    width=max(width)\n",
        "\n",
        "    print(len(b_box))\n",
        "    print(height)\n",
        "    print(int(np.mean(width)))\n",
        "    return b_box, height, width , segmentationssss, category_id \n",
        "  \n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    path = info['annotation']\n",
        "    b_box, segmentationssss, category_id, height, width = self.load_dataset(path)\n",
        "\n",
        "    masks = zeros([height, width, len(b_box)], dtype='uint8')\n",
        "    class_ids = list()\n",
        "\n",
        "    for i in range(len(b_box)):\n",
        "      box = b_box[i]\n",
        "      row_s, row_e = box[1], box[3]\n",
        "      col_s, col_e = box[0], box[2]\n",
        "      masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "      class_ids.append(self.class_names.index('fashion'))\n",
        "    return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info['path']\n",
        "\n",
        "print('##')\n",
        "# !ls\n",
        "# !pip list\n",
        "\n",
        "# this is the original path \n",
        "# \"python.pythonPath\": \"/usr/local/opt/python/bin/python3.7\",\n",
        "# need to set it back after deactivation\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd4m_mmuJaew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a configuration for the model\n",
        "class FashionConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"fashion_cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 1\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 131\n",
        "\n",
        "# prepare train set\n",
        "train_set = FashionDataset()\n",
        "train_set.load_dataset('fashion', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# prepare test/val set\n",
        "test_set = FashionDataset()\n",
        "test_set.load_dataset('fashion', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "# prepare config\n",
        "config = FashionConfig()\n",
        "config.display()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "\n",
        "model.load_weights('Mask_RCNN/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "# train weights (output layers or 'heads')\n",
        "# try:\n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')\n",
        "# except OSError:\n",
        "#   print('error')\n",
        "#   pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this error for running tf 2.0\n",
        "# it should be running tf 1.15 instead, because thats the version in the venv\n",
        "\n",
        "#somehow check the version\n",
        "# or pip install the version inside the python files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2T4B16IdzsD",
        "colab_type": "code",
        "outputId": "783df61c-6744-4947-996f-7ae4961e6dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_set = FashionDataset()\n",
        "train_set.load_dataset('fashion', is_train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6uOJalmRIQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_set.load_dataset('fashion', is_train=True)))\n",
        "print(len(test_set.load_dataset('fashion', is_train=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLdqKNwpQSpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}