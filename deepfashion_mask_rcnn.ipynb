{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepfashion mask rcnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b0iaT08-s0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # https://machinelearningmastery.com/how-to-perform-object-detection-in-photographs-with-mask-r-cnn-in-keras/\n",
        "# # https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/\n",
        "# # https://www.pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/\n",
        "# # https://towardsdatascience.com/webcam-object-detection-with-mask-r-cnn-on-google-colab-b3b012053ed1\n",
        "\n",
        "# tensorflow_version 1.x\n",
        "\n",
        "\n",
        "# #change add the Mask_RCNN directory to files. \n",
        "# # example: replace 'mrcnn' with:\n",
        "# # Mask_RCNN.mrcnn\n",
        "\n",
        "# # install mask_rcnn library or it's better to upload it, with the custom files.\n",
        "# !git clone https://github.com/matterport/Mask_RCNN.git\n",
        "\n",
        "# #istall some libraries from tpu\n",
        "# #!git clone https://github.com/tensorflow/tpu/\n",
        "\n",
        "# # import libraries required for the mask_rcnn library\n",
        "# !pip3 install -r 'Mask_RCNN/requirements.txt'\n",
        "# !cd Mask_RCNN ; python setup.py install\n",
        "\n",
        "# # download the Microsoft-coco dataset, in the mask_rcnn folder \n",
        "# !cd Mask_RCNN; wget 'https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5'\n",
        "\n",
        "# # download the an image of an elephant\n",
        "# !wget 'https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/03/elephant.jpg'\n",
        "\n",
        "# #download an image of a car\n",
        "# !wget 'https://i.insider.com/5d9b5bff52887931e8497a36'\n",
        "\n",
        "# # kangaroo dataset\n",
        "# !git clone https://github.com/experiencor/kangaroo.git\n",
        "# !cd\n",
        "\n",
        "# !unzip '/content/drive/My Drive/machinelearningdataset/DeepFashion2.zip'\n",
        "# print('')\n",
        "# print('')\n",
        "# print ('###################################all done###################################')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Lv55cZ_YKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # unzip deepfashion2 \n",
        "# # there's a file download limit for files from google drive. switch between the shared files from\n",
        "# # deepfashion2 and the files saved on the drive\n",
        "\n",
        "# #shared deepfashion2 dataset.\n",
        "# #!unzip -P 2019Deepfashion2** '/content/drive/My Drive/DeepFashion2 Dataset/json_for_validation.zip'\n",
        "\n",
        "# #  deepfashion2 dataset saved on google drive\n",
        "# !unzip -P 2019Deepfashion2** '/content/drive/My Drive/machinelearningdataset/json_for_validation.zip'\n",
        "# print('\\n','##########################done upzipping files.###########################################')\n",
        "# !unzip -P 2019Deepfashion2** '/content/drive/My Drive/machinelearningdataset/test.zip'\n",
        "# print('\\n','##########################done upzipping test files.###########################################')\n",
        "# !unzip -P 2019Deepfashion2** '/content/drive/My Drive/machinelearningdataset/train.zip'\n",
        "# print('\\n','##########################done upzipping train files.###########################################')\n",
        "# !unzip -P 2019Deepfashion2** '/content/drive/My Drive/machinelearningdataset/validation.zip'\n",
        "# print('\\n','##########################done upzipping validation files.###########################################')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already up-to-date: pip in /Users/ibrahim/.platformio/penv/lib/python3.7/site-packages (20.0.2)\nPackage                       Version  \n----------------------------- ---------\nabsl-py                       0.9.0    \nalabaster                     0.7.12   \nappnope                       0.1.0    \nastor                         0.8.1    \nattrs                         19.3.0   \nBabel                         2.8.0    \nbackcall                      0.1.0    \nbleach                        3.1.4    \nbottle                        0.12.17  \ncertifi                       2019.9.11\nchardet                       3.0.4    \nClick                         7.0      \ncolorama                      0.4.1    \ncycler                        0.10.0   \nCython                        0.29.16  \ndecorator                     4.4.2    \ndefusedxml                    0.6.0    \ndocutils                      0.16     \nentrypoints                   0.3      \ngast                          0.2.2    \ngoogle-pasta                  0.2.0    \ngrpcio                        1.27.2   \nh5py                          2.10.0   \nidna                          2.8      \nimageio                       2.8.0    \nimagesize                     1.2.0    \nimgaug                        0.4.0    \nimportlib-metadata            1.6.0    \nipykernel                     5.2.0    \nipyparallel                   6.2.4    \nipython                       7.13.0   \nipython-genutils              0.2.0    \nipywidgets                    7.5.1    \njedi                          0.16.0   \nJinja2                        2.11.1   \njsonschema                    3.2.0    \njupyter-client                6.1.2    \njupyter-core                  4.6.3    \nKeras                         2.2.5    \nKeras-Applications            1.0.8    \nKeras-Preprocessing           1.1.0    \nkiwisolver                    1.2.0    \nMarkdown                      3.2.1    \nMarkupSafe                    1.1.1    \nmarshmallow                   2.20.5   \nmatplotlib                    3.2.1    \nmistune                       0.8.4    \nnbconvert                     5.6.1    \nnbformat                      5.0.5    \nnetworkx                      2.4      \nnose                          1.3.7    \nnotebook                      6.0.3    \nnumpy                         1.18.2   \nopencv-python                 4.2.0.32 \nopt-einsum                    3.2.0    \npackaging                     20.3     \npandocfilters                 1.4.2    \nparso                         0.6.2    \npexpect                       4.8.0    \npickleshare                   0.7.5    \nPillow                        7.1.0    \npip                           20.0.2   \nplatformio                    4.3.1    \nprometheus-client             0.7.1    \nprompt-toolkit                3.0.5    \nprotobuf                      3.11.3   \nptyprocess                    0.6.0    \npyelftools                    0.25     \nPygments                      2.6.1    \npyparsing                     2.4.6    \npyrsistent                    0.16.0   \npyserial                      3.4      \npython-dateutil               2.8.1    \npytz                          2019.3   \nPyWavelets                    1.1.1    \nPyYAML                        5.3.1    \npyzmq                         19.0.0   \nqtconsole                     4.7.2    \nQtPy                          1.9.0    \nrequests                      2.22.0   \nscikit-image                  0.16.2   \nscipy                         1.4.1    \nsemantic-version              2.8.3    \nSend2Trash                    1.5.0    \nsetuptools                    46.1.3   \nShapely                       1.7.0    \nsix                           1.14.0   \nsnowballstemmer               2.0.0    \nSphinx                        2.4.4    \nsphinxcontrib-applehelp       1.0.2    \nsphinxcontrib-devhelp         1.0.2    \nsphinxcontrib-htmlhelp        1.0.3    \nsphinxcontrib-jsmath          1.0.1    \nsphinxcontrib-qthelp          1.0.3    \nsphinxcontrib-serializinghtml 1.1.4    \ntabulate                      0.8.6    \ntensorboard                   1.15.0   \ntensorflow                    1.15.0   \ntensorflow-estimator          1.15.1   \ntermcolor                     1.1.0    \nterminado                     0.8.3    \ntestpath                      0.4.4    \ntornado                       6.0.4    \ntraitlets                     4.3.3    \nurllib3                       1.25.7   \nwcwidth                       0.1.9    \nwebencodings                  0.5.1    \nWerkzeug                      1.0.1    \nwheel                         0.33.6   \nwidgetsnbextension            3.5.1    \nwrapt                         1.12.1   \nzipp                          3.1.0    \n/bin/sh: pinstall: command not found\nPackage                       Version  \n----------------------------- ---------\nabsl-py                       0.9.0    \nalabaster                     0.7.12   \nappnope                       0.1.0    \nastor                         0.8.1    \nattrs                         19.3.0   \nBabel                         2.8.0    \nbackcall                      0.1.0    \nbleach                        3.1.4    \nbottle                        0.12.17  \ncertifi                       2019.9.11\nchardet                       3.0.4    \nClick                         7.0      \ncolorama                      0.4.1    \ncycler                        0.10.0   \nCython                        0.29.16  \ndecorator                     4.4.2    \ndefusedxml                    0.6.0    \ndocutils                      0.16     \nentrypoints                   0.3      \ngast                          0.2.2    \ngoogle-pasta                  0.2.0    \ngrpcio                        1.27.2   \nh5py                          2.10.0   \nidna                          2.8      \nimageio                       2.8.0    \nimagesize                     1.2.0    \nimgaug                        0.4.0    \nimportlib-metadata            1.6.0    \nipykernel                     5.2.0    \nipyparallel                   6.2.4    \nipython                       7.13.0   \nipython-genutils              0.2.0    \nipywidgets                    7.5.1    \njedi                          0.16.0   \nJinja2                        2.11.1   \njsonschema                    3.2.0    \njupyter-client                6.1.2    \njupyter-core                  4.6.3    \nKeras                         2.2.5    \nKeras-Applications            1.0.8    \nKeras-Preprocessing           1.1.0    \nkiwisolver                    1.2.0    \nMarkdown                      3.2.1    \nMarkupSafe                    1.1.1    \nmarshmallow                   2.20.5   \nmatplotlib                    3.2.1    \nmistune                       0.8.4    \nnbconvert                     5.6.1    \nnbformat                      5.0.5    \nnetworkx                      2.4      \nnose                          1.3.7    \nnotebook                      6.0.3    \nnumpy                         1.18.2   \nopencv-python                 4.2.0.32 \nopt-einsum                    3.2.0    \npackaging                     20.3     \npandocfilters                 1.4.2    \nparso                         0.6.2    \npexpect                       4.8.0    \npickleshare                   0.7.5    \nPillow                        7.1.0    \npip                           20.0.2   \nplatformio                    4.3.1    \nprometheus-client             0.7.1    \nprompt-toolkit                3.0.5    \nprotobuf                      3.11.3   \nptyprocess                    0.6.0    \npyelftools                    0.25     \nPygments                      2.6.1    \npyparsing                     2.4.6    \npyrsistent                    0.16.0   \npyserial                      3.4      \npython-dateutil               2.8.1    \npytz                          2019.3   \nPyWavelets                    1.1.1    \nPyYAML                        5.3.1    \npyzmq                         19.0.0   \nqtconsole                     4.7.2    \nQtPy                          1.9.0    \nrequests                      2.22.0   \nscikit-image                  0.16.2   \nscipy                         1.4.1    \nsemantic-version              2.8.3    \nSend2Trash                    1.5.0    \nsetuptools                    46.1.3   \nShapely                       1.7.0    \nsix                           1.14.0   \nsnowballstemmer               2.0.0    \nSphinx                        2.4.4    \nsphinxcontrib-applehelp       1.0.2    \nsphinxcontrib-devhelp         1.0.2    \nsphinxcontrib-htmlhelp        1.0.3    \nsphinxcontrib-jsmath          1.0.1    \nsphinxcontrib-qthelp          1.0.3    \nsphinxcontrib-serializinghtml 1.1.4    \ntabulate                      0.8.6    \ntensorboard                   1.15.0   \ntensorflow                    1.15.0   \ntensorflow-estimator          1.15.1   \ntermcolor                     1.1.0    \nterminado                     0.8.3    \ntestpath                      0.4.4    \ntornado                       6.0.4    \ntraitlets                     4.3.3    \nurllib3                       1.25.7   \nwcwidth                       0.1.9    \nwebencodings                  0.5.1    \nWerkzeug                      1.0.1    \nwheel                         0.33.6   \nwidgetsnbextension            3.5.1    \nwrapt                         1.12.1   \nzipp                          3.1.0    \n"
        }
      ],
      "source": [
        "# create a virtual environment to run older version of tensorflow\n",
        "# mask rcnn runs on tf version 1.x\n",
        "\n",
        "# running venv on jupyter\n",
        "!python -m pip install --upgrade pip\n",
        "!python -m venv virtual_fashion\n",
        "!source virtual_fashion/bin/activate\n",
        "# !ipython kernel install --user --navirtual_fashion\n",
        "\n",
        "\n",
        "# running venv on jupyter\n",
        "!pip list\n",
        "!pinstall tf version 1.xpip install tensorflow==1.15\n",
        "!pip list\n",
        "\n",
        "#double cheking tf version. inside the venv, tf==1.15, outside, it's tf>2.0\n",
        "!python3 -c 'import tensorflow as tf; print(tf.__version__)'\n",
        "# setups related to  mask rcnn \n",
        "!pip3 install -r 'Mask_RCNN/requirements.txt'\n",
        "!cd Mask_RCNN ; python setup.py install# making sure that everything got installed properly\n",
        "!pip3 show mask-rcnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huRej0wRVl3o",
        "colab_type": "code",
        "outputId": "55781cc1-a4d0-43f9-97da-345df6e1fa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# convert the annonations to coco-compatible\n",
        "\n",
        "# upload the custom files (visualize.py and model.py) from 7gate_folder>Mask_RCNN>mrcnn\n",
        "# replace the deepfashion2_to_coco.py file in the DeepFashion2>evalation. from 7gate folder\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "img_folder_path = 'train/image'\n",
        "dirListing = os.listdir(img_folder_path)\n",
        "\n",
        "num_images= len(dirListing)\n",
        "print(num_images)\n",
        "!python DeepFashion2/evaluation/deepfashion2_to_coco.py"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "191961\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0U9z7jrxgdG",
        "colab_type": "code",
        "outputId": "1064510a-ec97-4c6f-d220-274d96a87fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from os import listdir\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "images_dir =  'train/image/'\n",
        "annotations_dir = 'train/annos/'\n",
        "count_index=0\n",
        "inner_count=0\n",
        "b_box=[]\n",
        "segmentationssss=list()\n",
        "category_id=list()\n",
        "width=list()\n",
        "height=[]\n",
        "for filename in listdir(images_dir):\n",
        "  count_index+=1\n",
        "  image_id = filename[:-4]\n",
        "  direecewdew= 'train/annos/' + image_id +'.json'\n",
        "  with open(direecewdew) as f:\n",
        "    data = f.read()\n",
        "    jsondata = json.loads(data)\n",
        "    for number in range(1,10):\n",
        "      item_number='item'+ str(number)\n",
        "      #print(item_number)\n",
        "      try:\n",
        "        b_box_iterate=jsondata.get(item_number)['bounding_box']\n",
        "        b_box.append(b_box_iterate)\n",
        "        segment=jsondata.get(item_number)['segmentation']\n",
        "        segmentationssss.append(segment)\n",
        "        category=jsondata.get(item_number)['category_id']\n",
        "        category_id.append(category)\n",
        "        w=b_box_iterate[2]\n",
        "        width.append(w)\n",
        "        h=b_box_iterate[3]\n",
        "        height.append(h)\n",
        "        img_path = images_dir + filename\n",
        "        ann_path = annotations_dir + image_id + '.json'\n",
        "        #self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "        #print(inner_count)\n",
        "        inner_count=+1\n",
        "        #print(inner_count)\n",
        "        #print(item_number)  \n",
        "      except Exception:\n",
        "        pass\n",
        "\n",
        "height=np.array(height)\n",
        "width=np.array(width)\n",
        "b_box=np.array(b_box)\n",
        "height=min(height)\n",
        "width=min(width)\n",
        "# print(count_index)\n",
        "# print(b_box)\n",
        "# print(height)\n",
        "# print(width)\n",
        "# print(segmentationssss)\n",
        "# print(category_id)\n",
        "# print(inner_count)\n",
        "\n",
        "print(len(b_box))\n",
        "print(height)\n",
        "print(int(np.mean(width)))\n",
        "\n",
        "#try it now.\n",
        "# there should be no more list eror in masks=zeroes[]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "312186\n0\n0\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9oLkGnqEPXb",
        "colab_type": "code",
        "outputId": "a2b64a3d-917d-4068-cd3c-cfd3dfe7cd4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from os import listdir\n",
        "import json\n",
        "import numpy as np\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from Mask_RCNN.mrcnn.utils import Dataset\n",
        "from Mask_RCNN.mrcnn.config import Config\n",
        "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
        "\n",
        "\n",
        "# class that defines and loads the kangaroo dataset\n",
        "class FashionDataset(Dataset):\n",
        "  def load_dataset(self, dataset_dir, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"fashion\")\n",
        "    images_dir =  'train/image/'\n",
        "    annotations_dir = 'train/annos/'\n",
        "    count_index=0\n",
        "    b_box=[]\n",
        "    segmentationssss=list()\n",
        "    category_id=list()\n",
        "    width=[]\n",
        "    height=[]\n",
        "    for filename in listdir(images_dir):\n",
        "      count_index+=1\n",
        "      image_id = filename[:-4]\n",
        "      direecewdew= 'train/annos/' + image_id +'.json'\n",
        "      with open(direecewdew) as f:\n",
        "        data = f.read()\n",
        "        jsondata = json.loads(data)\n",
        "        for number in range(1,10):\n",
        "          item_number='item'+ str(number)\n",
        "          try:\n",
        "            b_box_iterate=jsondata.get(item_number)['bounding_box']\n",
        "            b_box.append(b_box_iterate)\n",
        "            segment=jsondata.get(item_number)['segmentation']\n",
        "            segmentationssss.append(segment)\n",
        "            category=jsondata.get(item_number)['category_id']\n",
        "            category_id.append(category)\n",
        "            w=b_box_iterate[2]\n",
        "            width.append(w)\n",
        "            h=b_box_iterate[3]\n",
        "            height.append(h)\n",
        "            img_path = images_dir + filename\n",
        "            ann_path = annotations_dir + image_id + '.json'\n",
        "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "          except Exception:\n",
        "            pass\n",
        "    \n",
        "    height=np.array(height)\n",
        "    width=np.array(width)\n",
        "    b_box=np.array(b_box)\n",
        "    height=max(height)\n",
        "    width=max(width)\n",
        "\n",
        "    print(len(b_box))\n",
        "    print(height)\n",
        "    print(int(np.mean(width)))\n",
        "    return b_box, height, width , segmentationssss, category_id \n",
        "  \n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    path = info['annotation']\n",
        "    b_box, segmentationssss, category_id, height, width = self.load_dataset(path)\n",
        "    print(height)\n",
        "    print(width)\n",
        "    print(len(b_box))\n",
        "    masks = zeros([height, width, len(b_box)], dtype='uint8')\n",
        "    class_ids = list()\n",
        "\n",
        "    for i in range(len(b_box)):\n",
        "      box = b_box[i]\n",
        "      row_s, row_e = box[1], box[3]\n",
        "      col_s, col_e = box[0], box[2]\n",
        "      masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "      class_ids.append(self.class_names.index('fashion'))\n",
        "    return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info['path']\n",
        "\n",
        "print('##')\n",
        "!ls\n",
        "!pip list"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2.0.0\n##\n\u001b[30m\u001b[43mDeepFashion2\u001b[m\u001b[m                \u001b[34minclude\u001b[m\u001b[m\n\u001b[34mMask_RCNN\u001b[m\u001b[m                   \u001b[30m\u001b[43mjson_for_validation\u001b[m\u001b[m\nREADME.md                   \u001b[34mkangaroo\u001b[m\u001b[m\n\u001b[34mbin\u001b[m\u001b[m                         \u001b[34mlib\u001b[m\u001b[m\ncar.png                     pyvenv.cfg\ndeepfashion2.json           \u001b[34mtest\u001b[m\u001b[m\ndeepfashion_mask_rcnn.ipynb \u001b[34mtrain\u001b[m\u001b[m\nelephant.jpg                \u001b[34mvalidation\u001b[m\u001b[m\nUsing TensorFlow backend.\nPackage                       Version  \n----------------------------- ---------\nabsl-py                       0.9.0    \nalabaster                     0.7.12   \nappnope                       0.1.0    \nastor                         0.8.1    \nattrs                         19.3.0   \nBabel                         2.8.0    \nbackcall                      0.1.0    \nbleach                        3.1.4    \nbottle                        0.12.17  \ncertifi                       2019.9.11\nchardet                       3.0.4    \nClick                         7.0      \ncolorama                      0.4.1    \ncycler                        0.10.0   \nCython                        0.29.16  \ndecorator                     4.4.2    \ndefusedxml                    0.6.0    \ndocutils                      0.16     \nentrypoints                   0.3      \ngast                          0.2.2    \ngoogle-pasta                  0.2.0    \ngrpcio                        1.27.2   \n\nidna                          2.8      \nimageio                       2.8.0    \nimagesize                     1.2.0    \nimgaug                        0.4.0    \nimportlib-metadata            1.6.0    \nipykernel                     5.2.0    \nipyparallel                   6.2.4    \nipython                       7.13.0   \nipython-genutils              0.2.0    \nipywidgets                    7.5.1    \njedi                          0.16.0   \nJinja2                        2.11.1   \njsonschema                    3.2.0    \njupyter-client                6.1.2    \njupyter-core                  4.6.3    \nKeras                         2.2.5    \nKeras-Applications            1.0.8    \nKeras-Preprocessing           1.1.0    \nkiwisolver                    1.2.0    \nMarkdown                      3.2.1    \nMarkupSafe                    1.1.1    \nmarshmallow                   2.20.5   \nmask-rcnn                     2.1      \nmatplotlib                    3.2.1    \nmistune                       0.8.4    \nnbconvert                     5.6.1    \nnbformat                      5.0.5    \nnetworkx                      2.4      \nnose                          1.3.7    \nnotebook                      6.0.3    \nnumpy                         1.18.2   \nopencv-python                 4.2.0.32 \nopt-einsum                    3.2.0    \npackaging                     20.3     \npandocfilters                 1.4.2    \nparso                         0.6.2    \npexpect                       4.8.0    \npickleshare                   0.7.5    \nPillow                        7.1.0    \npip                           20.0.2   \nplatformio                    4.3.1    \nprometheus-client             0.7.1    \nprompt-toolkit                3.0.5    \nprotobuf                      3.11.3   \nptyprocess                    0.6.0    \npyelftools                    0.25     \nPygments                      2.6.1    \npyparsing                     2.4.6    \npyrsistent                    0.16.0   \npyserial                      3.4      \npython-dateutil               2.8.1    \npytz                          2019.3   \nPyWavelets                    1.1.1    \nPyYAML                        5.3.1    \npyzmq                         19.0.0   \nqtconsole                     4.7.2    \nQtPy                          1.9.0    \nrequests                      2.22.0   \nscikit-image                  0.16.2   \nscipy                         1.4.1    \nsemantic-version              2.8.3    \nSend2Trash                    1.5.0    \nsetuptools                    46.1.3   \nShapely                       1.7.0    \nsix                           1.14.0   \nsnowballstemmer               2.0.0    \nSphinx                        2.4.4    \nsphinxcontrib-applehelp       1.0.2    \nsphinxcontrib-devhelp         1.0.2    \nsphinxcontrib-htmlhelp        1.0.3    \nsphinxcontrib-jsmath          1.0.1    \nsphinxcontrib-qthelp          1.0.3    \nsphinxcontrib-serializinghtml 1.1.4    \ntabulate                      0.8.6    \ntensorboard                   1.15.0   \ntensorflow                    1.15.0   \ntensorflow-estimator          1.15.1   \ntermcolor                     1.1.0    \nterminado                     0.8.3    \ntestpath                      0.4.4    \ntornado                       6.0.4    \ntraitlets                     4.3.3    \nurllib3                       1.25.7   \nwcwidth                       0.1.9    \nwebencodings                  0.5.1    \nWerkzeug                      1.0.1    \nwheel                         0.33.6   \nwidgetsnbextension            3.5.1    \nwrapt                         1.12.1   \nzipp                          3.1.0    \n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd4m_mmuJaew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a configuration for the model\n",
        "class FashionConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"fashion_cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 1\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 131\n",
        "\n",
        "# prepare train set\n",
        "train_set = FashionDataset()\n",
        "train_set.load_dataset('fashion', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# prepare test/val set\n",
        "test_set = FashionDataset()\n",
        "test_set.load_dataset('fashion', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "# prepare config\n",
        "config = FashionConfig()\n",
        "config.display()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "\n",
        "model.load_weights('Mask_RCNN/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "# train weights (output layers or 'heads')\n",
        "# try:\n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')\n",
        "# except OSError:\n",
        "#   print('error')\n",
        "#   pass"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "312186\n1561\n1138\nTrain: 312186\n312186\n1561\n1138\nTest: 312186\n\nConfigurations:\nBACKBONE                       resnet101\nBACKBONE_STRIDES               [4, 8, 16, 32, 64]\nBATCH_SIZE                     2\nBBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\nCOMPUTE_BACKBONE_SHAPE         None\nDETECTION_MAX_INSTANCES        100\nDETECTION_MIN_CONFIDENCE       0.7\nDETECTION_NMS_THRESHOLD        0.3\nFPN_CLASSIF_FC_LAYERS_SIZE     1024\nGPU_COUNT                      1\nGRADIENT_CLIP_NORM             5.0\nIMAGES_PER_GPU                 2\nIMAGE_CHANNEL_COUNT            3\nIMAGE_MAX_DIM                  1024\nIMAGE_META_SIZE                14\nIMAGE_MIN_DIM                  800\nIMAGE_MIN_SCALE                0\nIMAGE_RESIZE_MODE              square\nIMAGE_SHAPE                    [1024 1024    3]\nLEARNING_MOMENTUM              0.9\nLEARNING_RATE                  0.001\nLOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\nMASK_POOL_SIZE                 14\nMASK_SHAPE                     [28, 28]\nMAX_GT_INSTANCES               100\nMEAN_PIXEL                     [123.7 116.8 103.9]\nMINI_MASK_SHAPE                (56, 56)\nNAME                           fashion_cfg\nNUM_CLASSES                    2\nPOOL_SIZE                      7\nPOST_NMS_ROIS_INFERENCE        1000\nPOST_NMS_ROIS_TRAINING         2000\nPRE_NMS_LIMIT                  6000\nROI_POSITIVE_RATIO             0.33\nRPN_ANCHOR_RATIOS              [0.5, 1, 2]\nRPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\nRPN_ANCHOR_STRIDE              1\nRPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\nRPN_NMS_THRESHOLD              0.7\nRPN_TRAIN_ANCHORS_PER_IMAGE    256\nSTEPS_PER_EPOCH                131\nTOP_DOWN_PYRAMID_SIZE          256\nTRAIN_BN                       False\nTRAIN_ROIS_PER_IMAGE           200\nUSE_MINI_MASK                  True\nUSE_RPN_ROIS                   True\nVALIDATION_STEPS               50\nWEIGHT_DECAY                   0.0001\n\n\n"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'random_shuffle'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-032981ea9abc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# load weights (mscoco) and exclude the output layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Downloads/fashion_mask_rcnn/virtual_fashion/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Downloads/fashion_mask_rcnn/virtual_fashion/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, mode, config)\u001b[0m\n\u001b[1;32m   1993\u001b[0m             \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m                 DetectionTargetLayer(config, name=\"proposal_targets\")([\n\u001b[0;32m-> 1995\u001b[0;31m                     target_rois, input_gt_class_ids, gt_boxes, input_gt_masks])\n\u001b[0m\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;31m# Network Heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Downloads/fashion_mask_rcnn/virtual_fashion/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    667\u001b[0m             lambda w, x, y, z: detection_targets_graph(\n\u001b[1;32m    668\u001b[0m                 w, x, y, z, self.config),\n\u001b[0;32m--> 669\u001b[0;31m             self.config.IMAGES_PER_GPU, names=names)\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Downloads/fashion_mask_rcnn/virtual_fashion/Mask_RCNN/mrcnn/utils.py\u001b[0m in \u001b[0;36mbatch_slice\u001b[0;34m(inputs, graph_fn, batch_size, names)\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0minputs_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0moutput_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0moutput_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Downloads/fashion_mask_rcnn/virtual_fashion/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(w, x, y, z)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             lambda w, x, y, z: detection_targets_graph(\n\u001b[0;32m--> 668\u001b[0;31m                 w, x, y, z, self.config),\n\u001b[0m\u001b[1;32m    669\u001b[0m             self.config.IMAGES_PER_GPU, names=names)\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Downloads/fashion_mask_rcnn/virtual_fashion/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mdetection_targets_graph\u001b[0;34m(proposals, gt_class_ids, gt_boxes, gt_masks, config)\u001b[0m\n\u001b[1;32m    556\u001b[0m     positive_count = int(config.TRAIN_ROIS_PER_IMAGE *\n\u001b[1;32m    557\u001b[0m                          config.ROI_POSITIVE_RATIO)\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0mpositive_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpositive_count\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m     \u001b[0mpositive_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;31m# Negative ROIs. Add enough to maintain positive:negative ratio.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'random_shuffle'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this error for running tf 2.0\n",
        "# it should be running tf 1.15 instead, because thats the version in the venv\n",
        "\n",
        "#somehow check the version\n",
        "# or pip install the version inside the python files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2T4B16IdzsD",
        "colab_type": "code",
        "outputId": "783df61c-6744-4947-996f-7ae4961e6dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_set = FashionDataset()\n",
        "train_set.load_dataset('fashion', is_train=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[226, 211, 526, 505], [197, 477, 594, 838]], [505, 838], [526, 594])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6uOJalmRIQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_set.load_dataset('fashion', is_train=True)))\n",
        "print(len(test_set.load_dataset('fashion', is_train=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLdqKNwpQSpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}